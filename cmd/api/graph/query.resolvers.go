package graph

import (
	"context"
	"encoding/json"
	"strconv"
	"time"

	"github.com/alim08/fin_line/pkg/models"
	"github.com/go-redis/redis/v8"
	"github.com/alim08/fin_line/pkg/metrics"
	"github.com/alim08/fin_line/pkg/logger"
	"go.uber.org/zap"
)

// Define the types that should be generated by gqlgen
type Quote struct {
	Ticker    string     `json:"ticker"`
	Price     float64    `json:"price"`
	Timestamp time.Time  `json:"timestamp"`
	Sector    *string    `json:"sector,omitempty"`
}

type Anomaly struct {
	ID        string    `json:"id"`
	Ticker    string    `json:"ticker"`
	Price     float64   `json:"price"`
	Threshold float64   `json:"threshold"`
	Type      string    `json:"type"`
	Timestamp time.Time `json:"timestamp"`
	Severity  string    `json:"severity"`
}

type MarketStats struct {
	TotalTickers int       `json:"total_tickers"`
	TotalQuotes  int       `json:"total_quotes"`
	AvgPrice     *float64  `json:"avg_price,omitempty"`
	LastUpdate   time.Time `json:"last_update"`
}

func (r *Resolver) Quotes(ctx context.Context, limit *int, ticker *string, sector *string) ([]*Quote, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/quotes", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/quotes", "200").Inc()
	}()

	// Set default limit
	queryLimit := 100
	if limit != nil && *limit > 0 && *limit <= 1000 {
		queryLimit = *limit
	}

	// Get quotes from Redis stream
	streamKey := "normalized:events"
	args := &redis.XReadArgs{
		Streams: []string{streamKey, "0"},
		Count:   int64(queryLimit),
		Block:   100 * time.Millisecond,
	}

	streams, err := r.redis.Client().XRead(ctx, args).Result()
	if err != nil && err != redis.Nil {
		logger.Log.Error("failed to read quotes stream", zap.Error(err))
		return nil, err
	}

	var quotes []*Quote
	if len(streams) > 0 && len(streams[0].Messages) > 0 {
		for _, msg := range streams[0].Messages {
			// Use the enhanced model parsing
			normalizedTick, err := models.NormalizedTickFromMap(msg.Values)
			if err != nil {
				logger.Log.Warn("failed to parse normalized tick", zap.Error(err), zap.String("id", msg.ID))
				continue
			}

			// Apply filters
			if ticker != nil && normalizedTick.Ticker != *ticker {
				continue
			}
			if sector != nil && normalizedTick.Sector != *sector {
				continue
			}

			quotes = append(quotes, &Quote{
				Ticker:    normalizedTick.Ticker,
				Price:     normalizedTick.Price,
				Timestamp: time.UnixMilli(normalizedTick.Timestamp),
				Sector:    &normalizedTick.Sector,
			})
		}
	}

	return quotes, nil
}

func (r *Resolver) Quote(ctx context.Context, ticker string) (*Quote, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/quote", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/quote", "200").Inc()
	}()

	// Get the latest quote for this ticker from Redis hash
	hashKey := "quotes:latest:" + ticker
	data, err := r.redis.HGetAll(ctx, hashKey).Result()
	if err != nil {
		logger.Log.Error("failed to get quote hash", zap.Error(err), zap.String("ticker", ticker))
		return nil, err
	}

	if len(data) == 0 {
		return nil, nil // Not found
	}

	// Parse price and timestamp
	priceStr, ok := data["price"]
	if !ok {
		logger.Log.Warn("missing price in quote hash", zap.String("ticker", ticker))
		return nil, nil
	}

	price, err := strconv.ParseFloat(priceStr, 64)
	if err != nil {
		logger.Log.Warn("invalid price in quote hash", zap.Error(err), zap.String("ticker", ticker))
		return nil, nil
	}

	tsMsStr, ok := data["ts_ms"]
	if !ok {
		logger.Log.Warn("missing timestamp in quote hash", zap.String("ticker", ticker))
		return nil, nil
	}

	tsMs, err := strconv.ParseInt(tsMsStr, 10, 64)
	if err != nil {
		logger.Log.Warn("invalid timestamp in quote hash", zap.Error(err), zap.String("ticker", ticker))
		return nil, nil
	}

	return &Quote{
		Ticker:    ticker,
		Price:     price,
		Timestamp: time.UnixMilli(tsMs),
		Sector:    nil, // Would need to get from separate lookup
	}, nil
}

func (r *Resolver) LatestQuotes(ctx context.Context) ([]*Quote, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/latest-quotes", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/latest-quotes", "200").Inc()
	}()

	// Get all quote hashes
	pattern := "quotes:latest:*"
	keys, err := r.redis.Client().Keys(ctx, pattern).Result()
	if err != nil {
		logger.Log.Error("failed to get quote keys", zap.Error(err))
		return nil, err
	}

	var quotes []*Quote
	for _, key := range keys {
		// Extract ticker from key
		ticker := key[len("quotes:latest:"):]
		
		// Get quote data
		data, err := r.redis.HGetAll(ctx, key).Result()
		if err != nil {
			logger.Log.Warn("failed to get quote hash", zap.Error(err), zap.String("key", key))
			continue
		}

		if len(data) == 0 {
			continue
		}

		// Parse data
		priceStr, ok := data["price"]
		if !ok {
			continue
		}

		price, err := strconv.ParseFloat(priceStr, 64)
		if err != nil {
			continue
		}

		tsMsStr, ok := data["ts_ms"]
		if !ok {
			continue
		}

		tsMs, err := strconv.ParseInt(tsMsStr, 10, 64)
		if err != nil {
			continue
		}

		quotes = append(quotes, &Quote{
			Ticker:    ticker,
			Price:     price,
			Timestamp: time.UnixMilli(tsMs),
			Sector:    nil,
		})
	}

	return quotes, nil
}

func (r *Resolver) Anomalies(ctx context.Context, limit *int, severity *string, typeArg *string) ([]*Anomaly, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/anomalies", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/anomalies", "200").Inc()
	}()

	// Set default limit
	queryLimit := 100
	if limit != nil && *limit > 0 && *limit <= 1000 {
		queryLimit = *limit
	}

	// Get anomalies from Redis stream
	streamKey := "anomalies:stream"
	args := &redis.XReadArgs{
		Streams: []string{streamKey, "0"},
		Count:   int64(queryLimit),
		Block:   100 * time.Millisecond,
	}

	streams, err := r.redis.Client().XRead(ctx, args).Result()
	if err != nil && err != redis.Nil {
		logger.Log.Error("failed to read anomalies stream", zap.Error(err))
		return nil, err
	}

	var result []*Anomaly
	if len(streams) > 0 && len(streams[0].Messages) > 0 {
		for _, msg := range streams[0].Messages {
			// Parse anomaly data
			anomaly, err := models.AnomalyFromMap(msg.Values)
			if err != nil {
				logger.Log.Warn("failed to parse anomaly", zap.Error(err), zap.String("id", msg.ID))
				continue
			}

			// Apply filters
			if severity != nil {
				// Would need severity field in Anomaly model
				// For now, skip filtering
			}
			if typeArg != nil {
				// Would need type field in Anomaly model
				// For now, skip filtering
			}

			result = append(result, &Anomaly{
				ID:        msg.ID,
				Ticker:    anomaly.Ticker,
				Price:     anomaly.Price,
				Threshold: anomaly.ZScore,
				Type:      "price_spike", // Default type
				Timestamp: time.UnixMilli(anomaly.Timestamp),
				Severity:  "medium", // Default severity
			})
		}
	}

	return result, nil
}

func (r *Resolver) AnomaliesByTicker(ctx context.Context, ticker string) ([]*Anomaly, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/anomalies-by-ticker", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/anomalies-by-ticker", "200").Inc()
	}()

	// Get anomalies from sorted set for specific ticker
	key := "anomalies:" + ticker
	anomalies, err := r.redis.Client().ZRange(ctx, key, 0, -1).Result()
	if err != nil && err != redis.Nil {
		logger.Log.Error("failed to get anomalies by ticker", zap.Error(err), zap.String("ticker", ticker))
		return nil, err
	}

	var result []*Anomaly
	for _, anomalyStr := range anomalies {
		var anomalyData map[string]interface{}
		if err := json.Unmarshal([]byte(anomalyStr), &anomalyData); err != nil {
			logger.Log.Warn("failed to unmarshal anomaly", zap.Error(err))
			continue
		}

		// Parse fields
		price, ok := anomalyData["price"].(float64)
		if !ok {
			continue
		}

		zScore, ok := anomalyData["z"].(float64)
		if !ok {
			continue
		}

		tsMs, ok := anomalyData["ts_ms"].(float64)
		if !ok {
			continue
		}

		result = append(result, &Anomaly{
			ID:        "generated", // Would need proper ID
			Ticker:    ticker,
			Price:     price,
			Threshold: zScore,
			Type:      "price_spike",
			Timestamp: time.UnixMilli(int64(tsMs)),
			Severity:  "medium",
		})
	}

	return result, nil
}

func (r *Resolver) Tickers(ctx context.Context) ([]string, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/tickers", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/tickers", "200").Inc()
	}()

	// Get all ticker keys
	pattern := "quotes:latest:*"
	keys, err := r.redis.Client().Keys(ctx, pattern).Result()
	if err != nil {
		logger.Log.Error("failed to get ticker keys", zap.Error(err))
		return nil, err
	}

	var tickers []string
	for _, key := range keys {
		ticker := key[len("quotes:latest:"):]
		tickers = append(tickers, ticker)
	}

	return tickers, nil
}

func (r *Resolver) Sectors(ctx context.Context) ([]string, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/sectors", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/sectors", "200").Inc()
	}()

	// This would need to be implemented based on your sector data
	// For now, return a static list
	return []string{"crypto", "stocks", "forex", "commodities"}, nil
}

func (r *Resolver) MarketStats(ctx context.Context) (*MarketStats, error) {
	start := time.Now()
	defer func() {
		metrics.APIRequestDuration.WithLabelValues("GET", "/market-stats", "200").Observe(time.Since(start).Seconds())
		metrics.APIRequestTotal.WithLabelValues("GET", "/market-stats", "200").Inc()
	}()

	// Get all ticker keys
	pattern := "quotes:latest:*"
	keys, err := r.redis.Client().Keys(ctx, pattern).Result()
	if err != nil {
		logger.Log.Error("failed to get market stats", zap.Error(err))
		return nil, err
	}

	totalTickers := len(keys)
	var totalQuotes int
	var totalPrice float64
	var lastUpdate time.Time

	// Calculate stats from all quotes
	for _, key := range keys {
		data, err := r.redis.HGetAll(ctx, key).Result()
		if err != nil {
			continue
		}

		if len(data) > 0 {
			totalQuotes++
			
			if priceStr, ok := data["price"]; ok {
				if price, err := strconv.ParseFloat(priceStr, 64); err == nil {
					totalPrice += price
				}
			}

			if tsMsStr, ok := data["ts_ms"]; ok {
				if tsMs, err := strconv.ParseInt(tsMsStr, 10, 64); err == nil {
					ts := time.UnixMilli(tsMs)
					if ts.After(lastUpdate) {
						lastUpdate = ts
					}
				}
			}
		}
	}

	var avgPrice *float64
	if totalQuotes > 0 {
		avg := totalPrice / float64(totalQuotes)
		avgPrice = &avg
	}

	return &MarketStats{
		TotalTickers: totalTickers,
		TotalQuotes:  totalQuotes,
		AvgPrice:     avgPrice,
		LastUpdate:   lastUpdate,
	}, nil
} 